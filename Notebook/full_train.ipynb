{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import numpy as np \n",
    "import os.path\n",
    "import random\n",
    "import json\n",
    "import sys\n",
    "import torch.optim as optim\n",
    "\n",
    "#Implementing seeds to be able to reproduce the experiments\n",
    "np.random.seed(999)\n",
    "random.seed(999)\n",
    "torch.manual_seed(999)\n",
    "torch.cuda.manual_seed_all(999)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Check if gpu support is available\n",
    "cuda_avail = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "grade_names = ['5+',\n",
    "               '6A', '6A+',\n",
    "               '6B', '6B+',\n",
    "               '6C', '6C+',\n",
    "               '7A', '7A+',\n",
    "               '7B', '7B+',\n",
    "               '7C', '7C+',\n",
    "               '8A', '8A+',\n",
    "               '8B', '8B+']\n",
    "\n",
    "n_grades = len(grade_names)\n",
    "save_directory = os.path.join('..', 'net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "from dataset import MoonboardProblemDataset\n",
    "json_data = []\n",
    "\n",
    "path_data=['../data/2017.json']\n",
    "for arg in path_data:\n",
    "    with open(arg) as input_file:\n",
    "        json_data += json.load(input_file)\n",
    "\n",
    "\n",
    "random.shuffle(json_data)\n",
    "#parametro2deentrada=float(sys.argv[2])\n",
    "train_set_size = int(0.7 * len(json_data))\n",
    "train_set = MoonboardProblemDataset(json_data[:train_set_size])\n",
    "valid_set = MoonboardProblemDataset(json_data[train_set_size:])\n",
    "\n",
    "params = {'batch_size': 128,\n",
    "          'shuffle': False,\n",
    "          'num_workers': 4}\n",
    "\n",
    "train_gen = data.DataLoader(train_set, **params)\n",
    "valid_gen = data.DataLoader(valid_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "class Unit(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Unit, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, kernel_size=3, out_channels=out_channels, stride=1, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.conv(input)\n",
    "        output = self.bn(output)\n",
    "        output = self.relu(output)\n",
    "        return output\n",
    "\n",
    "class DeepMoonClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=n_grades):\n",
    "        super(DeepMoonClassifier, self).__init__()\n",
    "\n",
    "        #Create 14 layers of the unit with max pooling in between\n",
    "        self.unit1 = Unit(in_channels=1, out_channels=32)\n",
    "        self.unit2 = Unit(in_channels=32, out_channels=32)\n",
    "        self.unit3 = Unit(in_channels=32, out_channels=32)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.unit4 = Unit(in_channels=32, out_channels=64)\n",
    "        self.unit5 = Unit(in_channels=64, out_channels=64)\n",
    "        self.unit6 = Unit(in_channels=64, out_channels=64)\n",
    "        self.unit7 = Unit(in_channels=64, out_channels=64)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.unit8 = Unit(in_channels=64, out_channels=64)\n",
    "        self.unit9 = Unit(in_channels=64, out_channels=64)\n",
    "        self.unit10 = Unit(in_channels=64, out_channels=64)\n",
    "        self.unit11 = Unit(in_channels=64, out_channels=64)\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.unit12 = Unit(in_channels=64, out_channels=128)\n",
    "        self.unit13 = Unit(in_channels=128, out_channels=128)\n",
    "        self.unit14 = Unit(in_channels=128, out_channels=128)\n",
    "        self.unit15 = Unit(in_channels=128, out_channels=128)\n",
    "        self.unit16 = Unit(in_channels=128, out_channels=128)\n",
    "        \n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=4)\n",
    "\n",
    "        #Add all the units into the Sequential layer in exact order\n",
    "        self.net = nn.Sequential(self.unit1, self.unit2, self.unit3, self.pool1, self.unit4,self.unit5,  self.unit6,\n",
    "                                 self.unit7, self.pool2, self.unit8, self.unit9, self.unit10, self.unit11,self.pool3,\n",
    "                                 self.unit12, self.avgpool)\n",
    "\n",
    "        self.fc = nn.Linear(in_features=128, out_features=num_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.net(input)\n",
    "        output = output.view(-1, 128)\n",
    "        output = self.fc(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model, optimizer and loss function\n",
    "model = DeepMoonClassifier(num_classes=n_grades)\n",
    "tensor_float_type = torch.FloatTensor\n",
    "#if cuda is available, move the model to the GPU\n",
    "if cuda_avail:\n",
    "    model.cuda()\n",
    "    tensor_float_type = torch.cuda.FloatTensor\n",
    "    # Uncomment for multi-GPU parallelism\n",
    "    #model = nn.DataParallel(model)\n",
    "\n",
    "#Define the optimizer and loss function\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "#Create a learning rate adjustment function that divides the learning rate by 10 every 30 epochs\n",
    "def adjust_learning_rate(epoch):\n",
    "\n",
    "    lr = 0.001\n",
    "\n",
    "    if epoch > 180:\n",
    "        lr = lr / 1000000\n",
    "    elif epoch > 150:\n",
    "        lr = lr / 100000\n",
    "    elif epoch > 120:\n",
    "        lr = lr / 10000\n",
    "    elif epoch > 90:\n",
    "        lr = lr / 1000\n",
    "    elif epoch > 60:\n",
    "        lr = lr / 100\n",
    "    elif epoch > 30:\n",
    "        lr = lr / 10\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def save_models(epoch):\n",
    "    if not os.path.exists(save_directory):\n",
    "        os.makedirs(save_directory)\n",
    "    torch.save(model.state_dict(), os.path.join(save_directory, 'classifier_{}.model'.format(epoch)))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_acc = 0.0\n",
    "    grade_hist = np.zeros((n_grades,), dtype=np.int)\n",
    "    acc_hist = tensor_float_type(n_grades).zero_()\n",
    "\n",
    "    for i, (problems, grades) in enumerate(valid_gen):\n",
    "        if cuda_avail:\n",
    "            problems = Variable(problems.cuda())\n",
    "            grades = Variable(grades.cuda())\n",
    "\n",
    "        #Predict classes using problems from the test set\n",
    "        outputs = model(problems)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        #print('pr', prediction)\n",
    "        #print('gt', grades.data)\n",
    "\n",
    "        #Compute accuracy\n",
    "        test_acc_float = 1 - (prediction - grades.data).abs_().type(tensor_float_type) / n_grades\n",
    "        acc_hist.index_add_(0, grades, test_acc_float)\n",
    "        local_hist, _ = np.histogram(grades.cpu(), bins=range(0, n_grades + 1))\n",
    "        grade_hist += local_hist\n",
    "        test_acc += test_acc_float.sum().item()\n",
    "\n",
    "    #Compute the average acc and loss over all test problems\n",
    "    test_acc = test_acc / len(valid_set)\n",
    "    acc_hist = acc_hist.cpu().numpy() / grade_hist\n",
    "    #print(grade_hist)\n",
    "    #print(acc_hist)\n",
    "\n",
    "    return test_acc, acc_hist\n",
    "\n",
    "def train(num_epochs):\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_acc = 0.0\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for i, (problems, grades) in enumerate(train_gen):\n",
    "            #Move problems and grades to gpu if available\n",
    "            if cuda_avail:\n",
    "                problems = Variable(problems.cuda())\n",
    "                grades = Variable(grades.cuda())\n",
    "\n",
    "            #Clear all accumulated gradients\n",
    "            optimizer.zero_grad()\n",
    "            #Predict classes using problems from the test set\n",
    "            outputs = model(problems)\n",
    "            #Compute the loss based on the predictions and actual grades\n",
    "            loss = loss_fn(outputs,grades)\n",
    "            #Backpropagate the loss\n",
    "            loss.backward()\n",
    "            #Adjust parameters according to the computed gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            #Compute accuracy\n",
    "            train_loss += loss.cpu().item() * problems.size(0)\n",
    "            _, prediction = torch.max(outputs.data, 1)\n",
    "            train_acc_float = 1 - (prediction - grades.data).abs_().type(tensor_float_type) / n_grades\n",
    "            train_acc += train_acc_float.sum().item()\n",
    "\n",
    "        #Call the learning rate adjustment function\n",
    "        adjust_learning_rate(epoch)\n",
    "\n",
    "        #Compute the average acc and loss over all training problems\n",
    "        train_acc = train_acc / len(train_set)\n",
    "        train_loss = train_loss / len(train_set)\n",
    "\n",
    "        #Evaluate on the test set\n",
    "        test_acc, acc_hist = test()\n",
    "\n",
    "        # Print the metrics\n",
    "        print('│ %05d │ %.16f │ %.16f │ %.16f ' % (epoch, train_loss, train_acc, test_acc), end='')\n",
    "\n",
    "        # Save the model if the test acc is greater than our current best\n",
    "        if test_acc > best_acc:\n",
    "            print('│   *   │')\n",
    "            save_models(epoch)\n",
    "            best_acc = test_acc\n",
    "            best_hist = acc_hist\n",
    "        else:\n",
    "            print('│       │')\n",
    "\n",
    "    return best_acc, best_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────┬────────────────────┬────────────────────┬────────────────────┬───────┐\n",
      "│ Epoch │     Train Loss     │   Train Accuracy   │   Valid Accuracy   │ Saved │\n",
      "├───────┼────────────────────┼────────────────────┼────────────────────┼───────┤\n",
      "tensor([ 2, 12,  2,  2,  3,  6, 12,  3,  5,  7,  4,  2,  2,  2,  7,  2,  5, 13,\n",
      "         8,  8,  2, 12,  6,  2, 10,  2,  4,  6,  5,  5,  2,  8,  8,  2, 12,  3,\n",
      "         3,  4,  2,  4,  2,  2,  7,  4,  6,  3, 11,  4,  3, 11,  4,  2,  6,  4,\n",
      "        11,  6,  7,  4,  2,  3,  8,  4,  3,  7,  3, 14,  3, 10,  3, 11,  6,  2,\n",
      "         5,  4, 11,  4,  7,  4,  0,  8,  3,  8,  5,  4,  4,  2,  4,  8,  5,  2,\n",
      "         4, 12,  4,  2,  5,  8,  2,  9,  7,  0, 10,  2,  6,  7,  4,  2, 10,  8,\n",
      "         6,  2,  6, 11,  5,  6,  7,  8,  6,  7,  7,  4,  2,  2,  6,  3,  3, 12,\n",
      "         7,  8])\n",
      "tensor([ 2,  8,  8, 10,  7,  3, 12,  7,  2, 13, 10,  4,  3,  6,  2,  2,  2,  2,\n",
      "         6,  2,  2,  5,  6,  7,  8,  2,  4,  8,  7,  8,  5,  2,  8,  3,  7,  2,\n",
      "         2,  8,  7,  0,  7,  2,  9,  8,  9,  3,  3,  5,  7,  6,  4,  7,  3,  2,\n",
      "         6,  5,  5,  6,  2,  2,  2,  5,  2,  5,  6,  0,  7,  2,  2,  3,  2,  4,\n",
      "         2,  4,  2,  5,  2,  7,  2, 11,  6,  3,  2,  2,  8,  2,  9,  8,  6,  2,\n",
      "         7, 10,  4,  2,  4,  5,  6,  7,  5,  2,  6,  4, 12,  2,  4,  3,  9, 10,\n",
      "         6,  9,  8,  4,  2,  5,  4,  5,  2,  3,  3,  2,  4,  5,  2,  7,  7,  1,\n",
      "         4,  6])\n",
      "tensor([ 7,  4, 11,  6,  6,  9,  6,  6,  6,  8,  3,  5,  7,  7, 11,  4,  7,  9,\n",
      "         2,  0,  2,  9,  8,  7,  2, 10,  8,  6,  2,  2,  2,  2,  2,  7,  2,  3,\n",
      "         2,  8,  6,  2,  8,  5,  2,  5,  6,  4,  2,  9,  3,  6,  3,  2,  5,  3,\n",
      "         8,  4,  4,  4, 12,  2,  3,  2,  7,  8,  6,  9,  5,  6,  6,  3,  5,  7,\n",
      "         4,  9,  3, 10,  4,  4,  6,  5,  4,  8,  8,  0,  6,  7,  7,  2,  6,  2,\n",
      "         6, 12,  2,  2,  7,  9,  3,  4,  4,  2,  4,  6,  7,  8,  7,  4,  4,  2,\n",
      "        11,  4,  7,  6,  9,  7,  2,  2, 10, 10,  8,  2,  8,  5, 10,  3,  2,  8,\n",
      "         8,  6])\n",
      "tensor([ 6,  2, 10,  2,  6,  2,  6,  3,  3,  8, 11,  4,  8,  2,  6, 10,  8,  3,\n",
      "         2,  7,  5,  8,  8,  6,  4,  2,  4,  4,  7,  7,  2,  8, 11, 11,  9,  0,\n",
      "         2,  2,  7,  4,  2,  2,  3,  6,  5,  4,  5,  8,  4,  6,  2,  7, 11,  2,\n",
      "         6,  0,  2,  4,  8,  7,  6,  5,  4,  2,  2,  4,  2,  0,  7,  6,  7,  6,\n",
      "         2,  6,  7,  6,  6,  9,  7,  4,  9,  4,  8,  0,  3,  7,  4,  7,  4,  3,\n",
      "         7,  3, 10,  3,  8,  4,  4,  7,  7,  6,  2,  4,  4, 11,  3,  7,  4,  3,\n",
      "         2,  4,  5, 10,  2,  5,  7,  6,  2,  7,  3, 11,  7,  8,  8,  2,  2,  6,\n",
      "         6,  2])\n",
      "tensor([ 9,  7, 10,  2,  2,  3,  3,  2,  4, 11,  2,  7,  4,  8,  5,  3,  5,  6,\n",
      "         7,  2,  2,  5,  7,  6,  2,  5,  5,  2,  6,  5,  9, 11,  3,  6,  2,  5,\n",
      "        10,  7,  4,  2,  3, 12,  2,  2,  2,  9,  2,  3,  3,  5,  2,  6,  9, 10,\n",
      "         6,  7,  2,  2,  5,  7,  7,  4,  4,  0,  3,  7,  4,  3,  2,  2,  7,  8,\n",
      "         7,  2,  2,  6,  5,  9,  8,  8,  7,  8,  4,  4,  6,  4,  2,  2,  5,  7,\n",
      "        10,  5,  6,  8,  9,  4,  2,  4,  8,  6,  7,  0,  6,  7,  3,  3,  3,  9,\n",
      "         8,  6,  8,  6,  3,  7,  2,  7,  5,  9,  3,  6,  1,  8, 11,  9,  4,  2,\n",
      "         3,  2])\n",
      "tensor([ 6,  5,  5, 11,  7,  3,  9,  3,  6,  7,  2,  2,  5,  2,  6,  4,  2,  6,\n",
      "         8,  6,  6,  5,  7,  8, 10,  6,  2,  6,  2,  2,  6,  5,  1,  2,  8, 11,\n",
      "         9,  6,  2,  3,  3, 10,  7,  8,  6,  2,  7,  0,  7,  4, 10,  6, 10,  8,\n",
      "         2,  5,  6,  3,  4,  2, 12,  7,  6,  8,  8,  9,  8,  2,  3,  6,  5,  2,\n",
      "         6,  4,  6,  4,  2,  9, 12,  2,  2,  4,  2,  5,  3,  6,  8,  7,  2,  8,\n",
      "         1,  5,  8,  9,  7,  2,  8,  5,  2,  2,  6,  7,  7,  2,  7,  2,  7, 11,\n",
      "         7,  6, 10,  9,  5,  4,  2,  2, 11,  2,  1,  2,  7,  8,  2,  2, 10,  6,\n",
      "         4,  5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-8e7b7017d4d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'│ Epoch │     Train Loss     │   Train Accuracy   │   Valid Accuracy   │ Saved │'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'├───────┼────────────────────┼────────────────────┼────────────────────┼───────┤'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'└───────┴────────────────────┴────────────────────┴────────────────────┴───────┘'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-1f95aa03d9af>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_epochs)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m#Predict classes using problems from the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0;31m#Compute the loss based on the predictions and actual grades\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrades\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-401ee5d1b447>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-401ee5d1b447>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1621\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1622\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m     )\n\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Trainning\n",
    "if __name__ == \"__main__\":\n",
    "    print('┌───────┬────────────────────┬────────────────────┬────────────────────┬───────┐')\n",
    "    print('│ Epoch │     Train Loss     │   Train Accuracy   │   Valid Accuracy   │ Saved │')\n",
    "    print('├───────┼────────────────────┼────────────────────┼────────────────────┼───────┤')\n",
    "    _, best_hist = train(int(20))\n",
    "    print('└───────┴────────────────────┴────────────────────┴────────────────────┴───────┘')\n",
    "    print('')\n",
    "    print('┌───────┬────────────────────┐')\n",
    "    print('│ Grade │      Accuracy      │')\n",
    "    print('├───────┼────────────────────┤')\n",
    "    result=[]\n",
    "\n",
    "    for i in range(0, n_grades):\n",
    "        print('│ % 5s │ %.16f │' % (grade_names[i], best_hist[i]))\n",
    "        result.append(best_hist[i])\n",
    "    print('└───────┴────────────────────┘')\n",
    "    print(np.mean(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "┌───────┬────────────────────┬────────────────────┬────────────────────┬───────┐\n",
    "│ Epoch │     Train Loss     │   Train Accuracy   │   Valid Accuracy   │ Saved │\n",
    "├───────┼────────────────────┼────────────────────┼────────────────────┼───────┤\n",
    "│ 00000 │ 2.2643498833585909 │ 0.8744745151311730 │ 0.8845882310867309 │   *   │"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
