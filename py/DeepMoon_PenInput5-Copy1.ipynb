{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this link we can find several architectures for generative models\n",
    "https://github.com/hwalsuklee/tensorflow-generative-model-collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas to implement\n",
    "> Modify the trainning architectre:\n",
    "        for generator: train_g for disc: train disc\n",
    "\n",
    "> Best practice: change the privacy of the variables -> ***Somewhat - Check***\n",
    "\n",
    "> Moduralize the trainning of G and D in the loop  -> ***Check***\n",
    "  \n",
    "> <font color='red'> Resnet to GANS? => ResGans</font> Squeeze-and-Excitation Networks (SENets)??\n",
    "\n",
    "> Can we apply penalty in both sides for faster convergence?\n",
    "\n",
    "> Introduce the nosie generator inside the networks -> ***Check*** -> El generador mantiene el output size del input\n",
    "\n",
    "> Define a late activation penalty function -> ***Check***\n",
    "\n",
    "> Plot number of cases that are valid  -> ***Check***\n",
    "\n",
    "> Modificar la arquitectura para que el penalty esté en el input\n",
    "\n",
    "> Modificar las arquitecturas de entrenamiento de G y D\n",
    "\n",
    "> Anadir DropOut a las NN. <font color='blue'> Tiene sentido implementar esto??</font>\n",
    "\n",
    "> Probar diferentes tipos de activation function as PRelu and Softplus\n",
    "\n",
    "> Add weight inizialization\n",
    "\n",
    "> Tiene sentido variar el gp_param?\n",
    "\n",
    "> Probar con 5 dimensiones una para cada penalty\n",
    "\n",
    "> Provar a activar el penalty mas tarde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> En que momento (dimensiones D)  aplicar el penalty input\n",
    "\n",
    "> Funcionamiento del upsample -> Adapta la imagen input al size indicado interpolando. Se pueden usar varios métodos\n",
    "\n",
    "> Tiene sentido implementar el Drop Out como método de regularización\n",
    "\n",
    "> Por que diverege lossD y lossG cuando ha pasado un gran numero de rondas -> Da la sensación de que podría ser debido a que anteriormente he usado torch.cat con una doble entrada de input. El back propagation aquí no queda claro lo que hace. \n",
    "\n",
    "> Gran diferencia entre Batch Norm y Instance norm. ¿¿Por??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "#from visdom import Visdom\n",
    "\n",
    "from dataset import DeepmoonDataset\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "Tensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import time\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#More libraries\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Using GPU:\" + str(use_cuda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix random seed: Pretty sure that this still doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 128\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "latent_size = 64     # Size of latent vector (i.e. size of generator input)\n",
    "n_features = 32      # Size of feature maps in generator\n",
    "lr = 0.0002\n",
    "betas = (0.5, 0.999) # Why is this not 0.9,0.9999 as standard?\n",
    "n_epochs = 500\n",
    "n_critic = 5\n",
    "n_print = 137\n",
    "gamma = 0.8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter for the WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_param=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paramaters for the constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_max = 2\n",
    "end_max = 2\n",
    "start_min = 1\n",
    "end_min = 1\n",
    "lmbda = 10  #Penalty parameter for constraints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def progressive_lambda(aIntEpoca,mode='constant'):\n",
    "    ''' Method that depending on the mode it calculates a lambda coeficient, the variable modes depend in the epoch'''\n",
    "    if mode == 'exponential':\n",
    "        r_0=0.001\n",
    "        tau=5\n",
    "        lam=r_0*np.exp(1+aIntEpoca/tau)\n",
    "        return lam\n",
    "    if mode == 'exp_base1.2':\n",
    "        r_0=0.005\n",
    "        tau=5\n",
    "        lam=r_0*1.2**(1+aIntEpoca/tau)\n",
    "        return lam\n",
    "    elif mode =='constant':\n",
    "        return 10\n",
    "    elif mode =='null':\n",
    "        return 0\n",
    "       \n",
    "    else:\n",
    "        return 0\n",
    "progressive_lambda(100,mode='null')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and split into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = '../data/2016.json'\n",
    "validation_split = 0.2\n",
    "\n",
    "dataset = DeepmoonDataset(json_path)\n",
    "\n",
    "split_len = [round((1-validation_split) * len(dataset)), round(validation_split * len(dataset))]\n",
    "split = {x: y for x, y in zip(['train', 'val'], data.random_split(dataset, lengths=split_len))}\n",
    "\n",
    "loader = {x: data.DataLoader(split[x], batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a convolutional and a deep convolutional units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose2d(64, 256, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace)\n",
       "    (9): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace)\n",
       "    (12): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (13): Sigmoid()\n",
       "    (14): Upsample(size=(18, 11), mode=nearest)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generator Code\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 32\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( latent_size, n_features * 8, 4, 1, 0),\n",
    "            nn.BatchNorm2d(n_features * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (n*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(n_features * 8, n_features * 4, 4, 2, 1),\n",
    "            nn.BatchNorm2d(n_features * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (n*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( n_features * 4, n_features * 2, 4, 2, 1),\n",
    "            nn.BatchNorm2d(n_features * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (n*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( n_features * 2, n_features, 4, 2, 1),\n",
    "            nn.BatchNorm2d(n_features),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (n) x 32 x 32\n",
    "            nn.ConvTranspose2d( n_features, nc, 4, 2, 1, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Upsample(size=(18, 11)) #Esto reordena los datos\n",
    "            \n",
    "            \n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self,asize):\n",
    "        x = torch.randn(asize, latent_size, 1, 1, device=device)\n",
    "        \n",
    "        return self.main(x)\n",
    "netG=Generator()\n",
    "netG.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([44, 3, 18, 11])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG(44).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (main): Sequential(\n",
       "    (0): Upsample(size=(32, 32), mode=nearest)\n",
       "    (1): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (6): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (9): Conv2d(128, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Upsample(size=(32, 32)),\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(ndf * 2),\n",
    "            #Hay una gran diferencia entre InstanceNormd y BatchNorm\n",
    "            # https://stackoverflow.com/questions/45463778/instance-normalisation-vs-batch-normalisation\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n",
    "            )\n",
    "  \n",
    "    def forward(self,x):        \n",
    "        return self.main(x).view(x.size(0), -1)\n",
    "    \n",
    "netD = Discriminator()\n",
    "netD.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizadores de las NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerD = torch.optim.Adam(netD.parameters(), lr, betas)\n",
    "optimizerG = torch.optim.Adam(netG.parameters(), lr, betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im not sure of what this function does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoundNoGradient(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        return x.round()\n",
    "    @staticmethod\n",
    "    def backward(ctx, g):\n",
    "        return g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define penalties"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "false=netG(torch.randn(128, latent_size, 1, 1, device=device))\n",
    "channel_penalty(false,2,2,1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 18, 11])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([44, 3, 18, 11])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG(44).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1.],\n",
       "          [0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0.],\n",
       "          [0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.],\n",
       "          [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1.],\n",
       "          [1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.],\n",
       "          [0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.],\n",
       "          [0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.],\n",
       "          [0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.]],\n",
       "\n",
       "         [[0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0.],\n",
       "          [0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.],\n",
       "          [1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0.],\n",
       "          [0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1.],\n",
       "          [0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.],\n",
       "          [1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
       "          [1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.],\n",
       "          [1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.],\n",
       "          [1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1.],\n",
       "          [1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.],\n",
       "          [1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1.]],\n",
       "\n",
       "         [[1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
       "          [1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
       "          [0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1.],\n",
       "          [0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.],\n",
       "          [1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.],\n",
       "          [1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
       "          [1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.],\n",
       "          [0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.]]]],\n",
       "       grad_fn=<RoundNoGradientBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RoundNoGradient.apply(netG(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 86.,  93.,  84.,  98.,  94.,  87.,  88.,  88.,  95.,  93.,  88.,  86.,\n",
       "         83.,  90.,  87.,  98.,  81., 102.,  87.,  90.,  84.,  86.,  90.,  97.,\n",
       "         90.,  91.,  90.,  90.,  85.,  91., 103.,  91.,  93.,  88.,  81.,  98.,\n",
       "         87.,  90.,  89.,  91., 104.,  90.,  91.,  87.,  86.,  95.,  80.,  88.,\n",
       "        101., 100.,  93.,  98.,  85.,  92.,  80.,  91., 104., 102.,  89.,  98.,\n",
       "         98.,  95.,  89.,  98.,  85.,  82., 102., 106.,  85.,  87.,  88.,  95.,\n",
       "         85.,  99.,  89.,  96.,  94.,  94.,  83.,  84.,  92.,  88.,  87.,  99.,\n",
       "         89.,  90.,  90.,  87., 101.,  91.,  89.,  84.,  95.,  85.,  91.,  77.,\n",
       "         93.,  82.,  90.,  93.,  90., 103.,  87.,  87.,  90.,  96.,  77.,  94.,\n",
       "         74.,  90.,  88.,  86.,  93.,  97.,  94.,  88.,  87.,  89.,  93.,  87.,\n",
       "         95.,  88.,  91.,  93.,  94.,  89., 100.,  97.],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=torch.sum(RoundNoGradient.apply(netG(128)),(2,3))[:,0]\n",
    "print(b.size())\n",
    "\n",
    "torch.relu(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 18, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0133)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(aa.size())\n",
    "torch.mean(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5156, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(netG(128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_penalty(x_fake):\n",
    "    # Este penalty recibe el input de la fake y comprueba si contiene el los iniciales y los finales adecuados\n",
    "    # devuelve un array del tamaño del input inicial\n",
    "    \n",
    "    count = torch.sum(RoundNoGradient.apply(x_fake), (2, 3))\n",
    "\n",
    "    count_start = count[:, 0]\n",
    "    count_end = count[:, 2]\n",
    "\n",
    "    g_start_max = torch.relu(count_start - start_max) ** 2\n",
    "    g_end_max = torch.relu(count_end - end_max) ** 2\n",
    "\n",
    "    g_start_min = torch.relu(-count_start + start_min) ** 2\n",
    "    g_end_min = torch.relu(-count_end + end_min) ** 2\n",
    "    return (g_start_max + g_end_max + g_start_min + g_end_min).view(x_fake.size(0), -1)\n",
    "\n",
    "def duplicate_penalty(x_fake):\n",
    "    count = torch.sum(RoundNoGradient.apply(x_fake), 1, keepdim=True)\n",
    "    g = torch.sum(torch.relu(count - 1) ** 2, (2, 3))\n",
    "    return g.view(x_fake.size(0), -1)\n",
    "\n",
    "def gradient_penalty(discriminator_net, x_real, x_fake):\n",
    "    batch_size = x_real.size(0)\n",
    "    # error*real +(1-error)*false -> Se suman ambas con un factor ruido\n",
    "    epsilon = torch.rand(batch_size, 1, 1, 1, device=device)\n",
    "    x_merged = (epsilon * x_real + (1 - epsilon) * x_fake).requires_grad_(True)\n",
    "    \n",
    "    #Se evalua el resultado de la suma de la combinacion linbeal de ambas\n",
    "    out_merged = discriminator_net(x_merged)\n",
    "\n",
    "    grad, = torch.autograd.grad(\n",
    "        outputs=out_merged,\n",
    "        inputs=x_merged,\n",
    "        grad_outputs=Tensor(batch_size, 1).fill_(1),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True)\n",
    "\n",
    "    return ((grad.view(batch_size, -1).norm(2, dim=1) - 1)**2).mean()\n",
    "\n",
    "def avg_start_end(x_fake):\n",
    "    count = torch.sum(x_fake.round(), (2, 3))\n",
    "\n",
    "    count_start = count[:, 0]\n",
    "    count_end = count[:, 2]\n",
    "\n",
    "    count_start.apply_(lambda x: 1 if start_max >= x >= start_min else 0)\n",
    "    count_end.apply_(lambda x: 1 if end_max >= x >= end_min else 0)\n",
    "\n",
    "    valid_solutions = Tensor([1 if s == 1 and e == 1 else 0\n",
    "                              for s, e in zip(count_start, count_end)])\n",
    "\n",
    "    return count_start.mean(), count_end.mean(), valid_solutions.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "channel\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(loader['train']):\n",
    "\n",
    "        x_real = data['moves'].type(Tensor)\n",
    "        if channel_penalty(x_real).sum()>0:\n",
    "            print(i)\n",
    "            print('channel')\n",
    "            print(channel_penalty(x_real).sum())\n",
    "        if duplicate_penalty(x_real).sum()>0:\n",
    "            print('duplicate')\n",
    "            print(duplicate_penalty(x_real).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty_extra_channel(image):\n",
    "    '''This method receives an image and returns it with one channel more.\n",
    "       This new channel has all the values the same and equal to the penalty'''\n",
    "    \n",
    "    # We add the penalty\n",
    "    pen_c = lmbda * channel_penalty(image)\n",
    "    pen_c = pen_c.unsqueeze(-1).unsqueeze(-1).expand(image.size(0), 1,image.size(2), image.size(3))\n",
    "    \n",
    "    \n",
    "    \n",
    "    out=torch.cat((image,pen_c), 1)\n",
    "    \n",
    "    pen_d = lmbda * duplicate_penalty(image)\n",
    "    \n",
    "    \n",
    "    pen_d = pen_d.unsqueeze(-1).unsqueeze(-1).expand(image.size(0), 1,image.size(2), image.size(3))\n",
    "    \n",
    "    return torch.cat((out,pen_d), 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 5, 18, 11])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG(128).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 7, 18, 11])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty_extra_channel(netG(128)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_solution_percent(imagen_falsa):\n",
    "    ''' From an image it calculates the % of images that satisfy the penalty'''\n",
    "    tens=channel_penalty(imagen_falsa) + duplicate_penalty(imagen_falsa)\n",
    "    \n",
    "    return (sum(1 for i in tens if i == 0 )/len(tens))*10 #We multiply this by 10 to scale it more visuable\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainning of the Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 18, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0133)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(aa.size())\n",
    "torch.mean(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 18, 11])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'penalty_extra_channel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d494c5cadec2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0maa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'moves'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0maa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpenalty_extra_channel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizerG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m113\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'penalty_extra_channel' is not defined"
     ]
    }
   ],
   "source": [
    "def train_generator(optim,real_data,epoch):\n",
    "    netG.zero_grad()\n",
    "\n",
    "    # Creamos una imagen falsa\n",
    "    x_fake = netG(real_data.size(0))\n",
    "    \n",
    "    # Calculamos el error del discriminador anadiento tanto la imagen falsa como el penalty\n",
    "    out_fake = netD(x_fake)\n",
    "    \n",
    "   \n",
    "    valid_solutions=valid_solution_percent(x_fake)                       \n",
    "    \n",
    "\n",
    "    lossG = -torch.mean(out_fake) \\\n",
    "\n",
    "    lossG.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    return lossG,valid_solutions\n",
    "\n",
    "for i, data in enumerate(loader['train']):\n",
    "\n",
    "\n",
    "    aa = data['moves'].type(Tensor)\n",
    "    print(aa.size())\n",
    "    aa = penalty_extra_channel(aa)\n",
    "    a,b=train_generator(optimizerG,aa,113)\n",
    "    \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 5, 18, 11])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 18, 11])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pen_c=lmbda * (channel_penalty(aa))\n",
    "print(pen_c.size())\n",
    "pen_c = pen_c.unsqueeze(-1).unsqueeze(-1).expand(aa.size(0), 1,aa.size(2), aa.size(3))\n",
    "pen_c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 1., 0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 1., 0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 1., 0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty_extra_channel(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in netD.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        if name=='fc.0.bias' or name=='fc.0.weight':\n",
    "            print (name,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22.8962, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def train_discriminator(optim,real_data):\n",
    "   \n",
    "    netD.zero_grad()\n",
    "    \n",
    "    x_fake = netG(real_data.size(0))\n",
    "    \n",
    "    #Hacemos la predicción de la imagen con el discriminador para el real y el fake\n",
    "    out_real = netD(real_data)\n",
    "    out_fake = netD(x_fake)\n",
    "    \n",
    "\n",
    "    #Anadimos la loss function interpolando entre la media del error de la real y de fake\n",
    "    # introducimos el valor del penalty\n",
    "    error_d = torch.mean(out_fake) - torch.mean(out_real) + gp_param * gradient_penalty(netD, real_data.data, x_fake.data) \n",
    "    #Hacemos el backward propagation y damos un step en la dirección del gradiente \n",
    "        # del discriminador\n",
    "    error_d.backward(retain_graph=True)\n",
    "    optim.step()\n",
    "   \n",
    "    return error_d\n",
    "\n",
    "for i, data in enumerate(loader['train']):\n",
    "    epoch=30\n",
    "\n",
    "\n",
    "    aa = data['moves'].type(Tensor)\n",
    "    aa=penalty_extra_channel(aa)\n",
    "    \n",
    "    a=train_discriminator(optimizerD,aa)\n",
    "    print(a)\n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cummulative Lists\n",
    "fixed_noise = torch.randn(128, latent_size, 1, 1, device=device)\n",
    "\n",
    "history = {'lossD': [], 'lossG': [], 'avgStart': [], 'avgEnd': [],\n",
    "           'valid': [], 'validHist': [], 'imgs': [],'epoch': [],\n",
    "           'porcentaje' : []}\n",
    "\n",
    "epoch=-1 #Instanciamos esta variable fuera para poder repetir entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/cmougan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-e0999abd5a55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mlossD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizerD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-151-da64b5fced90>\u001b[0m in \u001b[0;36mtrain_discriminator\u001b[0;34m(optim, real_data)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#Hacemos el backward propagation y damos un step en la dirección del gradiente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# del discriminador\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0merror_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while epoch<n_epochs:\n",
    "    epoch+=1\n",
    "\n",
    "    for i, data in enumerate(loader['train']):\n",
    "\n",
    "        x_real = data['moves'].type(Tensor)\n",
    "        x_real = penalty_extra_channel(x_real)\n",
    "        N = x_real.size(0)\n",
    "        \n",
    "        lossD = train_discriminator(optimizerD,x_real)\n",
    "\n",
    "\n",
    "        # En un número ciclico de veces entrenamos el Generador\n",
    "        if i % n_critic == 0:\n",
    "\n",
    "            lossG,perc = train_generator(optimizerG,x_real,epoch)\n",
    "\n",
    "        # Print training stats\n",
    "        if i % n_print == 0 and epoch>1:\n",
    "            \n",
    "            plt.figure()\n",
    "            \n",
    "            #plt.plot(history['lossD'],'r',label='loss_Discriminator')\n",
    "            #plt.plot(history['lossG'],'k',label='loss_Generator')\n",
    "            plt.plot(history['porcentaje'],label='Percentage')\n",
    "            \n",
    "            plt.legend(loc=(0,0.8))\n",
    "           \n",
    "\n",
    "            \n",
    "            plt.title('Porcentaje in epoch {} with 4 channels'.format(epoch))\n",
    "            plt.savefig('../imagenes/with4channels'.format(epoch))\n",
    "            \n",
    "            display.clear_output(wait=False)\n",
    "            display.display(plt.gcf())\n",
    "            time.sleep(1)\n",
    "            print(\n",
    "                \"[Epoch {:5}/{:5}] [Batch {:3}/{:3}] [D loss: {:2.6f}] [G loss: {:2.6f}] percent {}\".format(\n",
    "                    epoch, n_epochs, i, len(loader['train']), lossD.item(), lossG.item(),perc/10\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "    # Save losses in history and update plot\n",
    "    with torch.no_grad():\n",
    "        history['imgs'] += [netG(x_real.size(0)).detach().cpu()]\n",
    "        avgStart, avgEnd, valid = avg_start_end(history['imgs'][-1].detach())\n",
    "\n",
    "    history['lossD'] += [lossD.item()]\n",
    "    history['lossG'] += [lossG.item()]\n",
    "    history['avgStart'] += [avgStart.item()]\n",
    "    history['avgEnd'] += [avgEnd.item()]\n",
    "    history['valid'] += [valid.item()]\n",
    "    history['validHist'] += [sum(history['valid'][-20:]) / len(history['valid'][-20:])]\n",
    "    history['epoch'] += [epoch]\n",
    "    history['porcentaje'] += [perc]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen = lmbda * (channel_penalty(aa) + duplicate_penalty(aa))\n",
    "print(pen.size())\n",
    "pen.unsqueeze_(-1)\n",
    "pen.expand(128,3,10)\n",
    "pen.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = Variable(torch.zeros(128, 1,18,11).cuda())\n",
    "\n",
    "torch.cat((aa,extra), 1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = Variable(torch.zeros(128, 1,18,11).cuda())                     \n",
    "# We add the penalty\n",
    "pen = lmbda * (channel_penalty(aa) + duplicate_penalty(aa))\n",
    "torch.cat((aa,extra), 1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen.unsqueeze(-1).unsqueeze(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen.unsqueeze(-1).unsqueeze(-1).expand(128,1,18,11).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen.expand_as(extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "up=nn.UpsamplingNearest2d(size=(18,11))\n",
    "up(pen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Variable(torch.randn(10, 3, 24, 24))\n",
    "m = nn.UpsamplingNearest2d(size=(55, 55))\n",
    "out = m(inp)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
