{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "#from visdom import Visdom\n",
    "\n",
    "from dataset import DeepmoonDataset\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "Tensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import time\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#More libraries\n",
    "import random\n",
    "\n",
    "\n",
    "print(\"Using GPU:\" + str(use_cuda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 128\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "latent_size = 64\n",
    "n_features = 32\n",
    "lr = 0.0002\n",
    "betas = (0.5, 0.999)\n",
    "n_epochs = 10000\n",
    "n_critic = 5\n",
    "n_print = 137\n",
    "gamma = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paramaters for the constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_max = 2\n",
    "end_max = 2\n",
    "start_min = 1\n",
    "end_min = 1\n",
    "lmbda = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and split into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = '../data/2016.json'\n",
    "validation_split = 0.2\n",
    "\n",
    "dataset = DeepmoonDataset(json_path)\n",
    "\n",
    "split_len = [round((1-validation_split) * len(dataset)), round(validation_split * len(dataset))]\n",
    "split = {x: y for x, y in zip(['train', 'val'], data.random_split(dataset, lengths=split_len))}\n",
    "\n",
    "loader = {x: data.DataLoader(split[x], batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a convolutional and a deep convolutional units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCUnit(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(DCUnit, self).__init__()\n",
    "        self.dcunit = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dcunit(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CUnit(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(CUnit, self).__init__()\n",
    "        self.cunit = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cunit(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_size, n_features):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dcnn = nn.Sequential(\n",
    "            DCUnit(latent_size, 4 * n_features, 4, 1, 0),\n",
    "            DCUnit(4 * n_features, 2 * n_features, 4, 2, 1),\n",
    "            DCUnit(2 * n_features, n_features, 4, 2, 1),\n",
    "\n",
    "            nn.ConvTranspose2d(n_features, 3, 4, 2, 1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Upsample(size=(18, 11))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dcnn(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Upsample(size=(32, 32)),\n",
    "\n",
    "            CUnit(3, n_features, 4, 2, 1),\n",
    "            CUnit(n_features, 2 * n_features, 4, 2, 1),\n",
    "            CUnit(2 * n_features, 4 * n_features, 4, 2, 1),\n",
    "\n",
    "            nn.Conv2d(4 * n_features, 1, 4, 1, 0),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(nn.Linear(1 + 1, 32),nn.Linear(32, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        img, penalty = x\n",
    "        out_img = self.cnn(img).view(img.size(0), -1)\n",
    "        inputs = torch.cat([out_img, penalty], dim=1)\n",
    "        return self.fc(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (cnn): Sequential(\n",
       "    (0): Upsample(size=(32, 32), mode=nearest)\n",
       "    (1): CUnit(\n",
       "      (cunit): Sequential(\n",
       "        (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "      )\n",
       "    )\n",
       "    (2): CUnit(\n",
       "      (cunit): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "      )\n",
       "    )\n",
       "    (3): CUnit(\n",
       "      (cunit): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "      )\n",
       "    )\n",
       "    (4): Conv2d(128, 1, kernel_size=(4, 4), stride=(1, 1))\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG = Generator(latent_size, n_features)\n",
    "netD = Discriminator(n_features)\n",
    "netG.to(device)\n",
    "netD.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerD = torch.optim.Adam(netD.parameters(), lr, betas)\n",
    "optimizerG = torch.optim.Adam(netG.parameters(), lr, betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im not sure of what this function does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoundNoGradient(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        return x.round()\n",
    "    @staticmethod\n",
    "    def backward(ctx, g):\n",
    "        return g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_penalty(x_fake, start_max, end_max, start_min, end_min):\n",
    "    count = torch.sum(RoundNoGradient.apply(x_fake), (2, 3))\n",
    "\n",
    "    count_start = count[:, 0]\n",
    "    count_end = count[:, 2]\n",
    "\n",
    "    g_start_max = torch.relu(count_start - start_max) ** 2\n",
    "    g_end_max = torch.relu(count_end - end_max) ** 2\n",
    "\n",
    "    g_start_min = torch.relu(-count_start + start_min) ** 2\n",
    "    g_end_min = torch.relu(-count_end + end_min) ** 2\n",
    "    return (g_start_max + g_end_max + g_start_min + g_end_min).view(x_fake.size(0), -1)\n",
    "\n",
    "def duplicate_penalty(x_fake):\n",
    "    count = torch.sum(RoundNoGradient.apply(x_fake), 1, keepdim=True)\n",
    "    g = torch.sum(torch.relu(count - 1) ** 2, (2, 3))\n",
    "    return g.view(x_fake.size(0), -1)\n",
    "\n",
    "def gradient_penalty(D, x_real, x_fake,penalty):\n",
    "    batch_size = x_real.size(0)\n",
    "\n",
    "    epsilon = torch.rand(batch_size, 1, 1, 1, device=device)\n",
    "    x_merged = (epsilon * x_real + (1 - epsilon) * x_fake).requires_grad_(True)\n",
    "    out_merged = D((x_merged, penalty))\n",
    "\n",
    "    grad, = torch.autograd.grad(\n",
    "        outputs=out_merged,\n",
    "        inputs=x_merged,\n",
    "        grad_outputs=Tensor(batch_size, 1).fill_(1),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )\n",
    "\n",
    "    return ((grad.view(batch_size, -1).norm(2, dim=1) - 1)**2).mean()\n",
    "\n",
    "def avg_start_end(x_fake, start_max, end_max, start_min, end_min):\n",
    "    count = torch.sum(x_fake.round(), (2, 3))\n",
    "\n",
    "    count_start = count[:, 0]\n",
    "    count_end = count[:, 2]\n",
    "\n",
    "    count_start.apply_(lambda x: 1 if start_max >= x >= start_min else 0)\n",
    "    count_end.apply_(lambda x: 1 if end_max >= x >= end_min else 0)\n",
    "\n",
    "    valid_solutions = Tensor([1 if s == 1 and e == 1 else 0\n",
    "                              for s, e in zip(count_start, count_end)])\n",
    "\n",
    "    return count_start.mean(), count_end.mean(), valid_solutions.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch=1000\n",
    "4 if epoch > 100 else torch.zeros([10, 1], device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmougan/anaconda3/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1970, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "def train_generator(optim,real_data,epoch):\n",
    "    netG.zero_grad()\n",
    "\n",
    "    # Creamos una imagen falsa\n",
    "    x_fake = netG(torch.randn(real_data.size(0), latent_size, 1, 1, device=device))\n",
    "\n",
    "     #Calculamos los penalties a esta imagen\n",
    "    penalty = 0.1 * channel_penalty(x_fake, start_max, end_max, start_min, end_min) + 0.1 * duplicate_penalty(x_fake) if epoch > 100 else torch.zeros([real_data.size(0), 1], device=device)\n",
    "\n",
    "            # Calculamos el error del discriminador anadiento tanto la imagen falsa como el penalty\n",
    "    out_fake = netD((x_fake, penalty))\n",
    "\n",
    "    lossG = -torch.mean(out_fake) \\\n",
    "\n",
    "    lossG.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    return lossG\n",
    "\n",
    "for i, data in enumerate(loader['train']):\n",
    "    aa = data['moves'].type(Tensor)\n",
    "    a=train_generator(optimizerG,aa,0)\n",
    "    print(a)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(684.9302, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def train_discriminator(optim,real_data):\n",
    "   \n",
    "    netD.zero_grad()\n",
    "    # Creamos un set de números aleatorios y producimos una imagen con ellos\n",
    "    z = torch.randn(real_data.size(0), latent_size, 1, 1, device=device)\n",
    "    x_fake = netG(z)\n",
    "    \n",
    "    # Computamos los penalty (definidos en las funciones anteriores)\n",
    "    penalty = 0.1 * channel_penalty(x_fake, start_max, end_max, start_min, end_min) + 0.1 * duplicate_penalty(x_fake) if epoch > 100 else torch.zeros([N, 1], device=device)\n",
    "\n",
    "    \n",
    "    #Hacemos la predicción de la imagen con el discriminador para el real y el fake\n",
    "    out_real = netD((real_data, torch.zeros([real_data.size(0), 1], device=device)))\n",
    "    out_fake = netD((x_fake, penalty))\n",
    "\n",
    "    #Anadimos la loss function interpolando entre la media del error de la real y de fake\n",
    "    # introducimos el valor del penalty\n",
    "    error_d = torch.mean(out_fake) - torch.mean(out_real) + lmbda * gradient_penalty(netD, real_data.data, x_fake.data,penalty) \n",
    "    #Hacemos el backward propagation y damos un step en la dirección del gradiente \n",
    "        # del discriminador\n",
    "    error_d.backward(retain_graph=True)\n",
    "    optim.step()\n",
    "\n",
    "    \n",
    "    return error_d\n",
    "for i, data in enumerate(loader['train']):\n",
    "    aa = data['moves'].type(Tensor)\n",
    "    a=train_discriminator(optimizerD,aa)\n",
    "    print(a)\n",
    "    break\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-225faebfd41c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mZ2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m im2 = plt.imshow(b, cmap='mako', alpha=1, interpolation='bilinear',\n\u001b[0m\u001b[1;32m     33\u001b[0m                  extent=extent)\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def func3(x, y):\n",
    "    return (1 - x / 2 + x**5 + y**3) * np.exp(-(x**2 + y**2))\n",
    "\n",
    "\n",
    "# make these smaller to increase the resolution\n",
    "dx, dy = 0.05, 0.05\n",
    "\n",
    "x = np.arange(-3.0, 3.0, dx)\n",
    "y = np.arange(-3.0, 3.0, dy)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# when layering multiple images, the images need to have the same\n",
    "# extent.  This does not mean they need to have the same shape, but\n",
    "# they both need to render to the same coordinate system determined by\n",
    "# xmin, xmax, ymin, ymax.  Note if you use different interpolations\n",
    "# for the images their apparent extent could be different due to\n",
    "# interpolation edge effects\n",
    "\n",
    "extent = np.min(x), np.max(x), np.min(y), np.max(y)\n",
    "fig = plt.figure(frameon=False)\n",
    "\n",
    "Z1 = np.add.outer(range(8), range(8)) % 2  # chessboard\n",
    "im1 = plt.imshow(Z1, cmap=plt.cm.gray, interpolation='nearest',\n",
    "                 extent=extent)\n",
    "\n",
    "Z2 = func3(X, Y)\n",
    "\n",
    "im2 = plt.imshow(b, cmap='mako', alpha=1, interpolation='bilinear',\n",
    "                 extent=extent)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa[2][0][17][9]=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10.,  0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[1][1][3][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jjj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-afe1191027e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjjj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'jjj' is not defined"
     ]
    }
   ],
   "source": [
    "jjj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dimension specified as 0 but tensor has no dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-4c52d3f7e1da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m41\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: dimension specified as 0 but tensor has no dimensions"
     ]
    }
   ],
   "source": [
    "a[41][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=41\n",
    "a = aa\n",
    "a[i][2][17][1]=1\n",
    "#a[i][][17][9]= 1\n",
    "b = 3*(a[i][0])+10*a[i][1]+15*a[i][2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 11])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = torch.zeros_like(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb[0][6] = 3\n",
    "\n",
    "bb[1][8] = 10\n",
    "bb[4][8] = 10\n",
    "bb[6][10] = 10\n",
    "bb[8][9] = 10\n",
    "bb[10][9] = 10\n",
    "bb[12][7] = 10\n",
    "\n",
    "bb[13][10] = 15\n",
    "bb[16][7] = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  3.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 15.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0., 15.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(b, cmap='mako')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.heatmap(bb, linewidth=0.9, cmap=\"Reds\")\n",
    "ax.set(xticklabels=[''])\n",
    "ax.set(yticklabels=[])\n",
    "plt.savefig('encodingmoond.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(128, latent_size, 1, 1, device=device)\n",
    "\n",
    "history = {'lossD': [], 'lossG': [], 'avgStart': [], 'avgEnd': [],\n",
    "           'valid': [], 'validHist': [], 'imgs': [],'epoch': []}\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    for i, data in enumerate(loader['train']):\n",
    "\n",
    "        x_real = data['moves'].type(Tensor)\n",
    "        break\n",
    "       \n",
    "\n",
    "       \n",
    "        N = x_real.size(0)\n",
    "        \n",
    "        lossD = train_discriminator(optimizerD,x_real)\n",
    "\n",
    "        # En un número ciclico de veces entrenamos el Generador\n",
    "        if i % n_critic == 0:\n",
    "\n",
    "            lossG = train_generator(optimizerG,x_real,epoch)\n",
    "\n",
    "        # Print training stats\n",
    "        if i % n_print == 0:\n",
    "            \n",
    "            plt.figure()\n",
    "            plt.plot(history['lossD'],'r',label='loss_Discriminator')\n",
    "            plt.plot(history['lossG'],'k',label='loss_Generator')\n",
    "            plt.plot(history['avgStart'],'*b',label='Average Start')\n",
    "            plt.plot(history['avgEnd'],'*y',label='Average End')\n",
    "            \n",
    "            plt.legend(loc=(1,0.7))\n",
    "            \n",
    "            try:\n",
    "                plt.title('Generator and Discriminator loss evolution in epoch: {}'.format(history['epoch'][-1]))\n",
    "            except:\n",
    "                plt.title('Generator and Discriminator loss evolution in epoch: 0')\n",
    "            \n",
    "            display.clear_output(wait=False)\n",
    "            display.display(plt.gcf())\n",
    "            time.sleep(1)\n",
    "            print(\n",
    "                \"[Epoch {:5}/{:5}] [Batch {:3}/{:3}] [D loss: {:2.6f}] [G loss: {:2.6f}]\".format(\n",
    "                    epoch, n_epochs, i, len(loader['train']), lossD.item(), lossG.item()\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "    # Save losses in history and update plot\n",
    "    with torch.no_grad():\n",
    "        history['imgs'] += [netG(fixed_noise).detach().cpu()]\n",
    "        avgStart, avgEnd, valid = avg_start_end(history['imgs'][-1].detach(), start_max, end_max, start_min, end_min)\n",
    "\n",
    "    history['lossD'] += [lossD.item()]\n",
    "    history['lossG'] += [lossG.item()]\n",
    "    history['avgStart'] += [avgStart.item()]\n",
    "    history['avgEnd'] += [avgEnd.item()]\n",
    "    history['valid'] += [valid.item()]\n",
    "    history['validHist'] += [sum(history['valid'][-20:]) / len(history['valid'][-20:])]\n",
    "    history['epoch'] += [epoch]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
